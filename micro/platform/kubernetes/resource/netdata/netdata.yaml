---
# Source: netdata/templates/psp.yaml
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: infra-netdata-psp
  labels:
    heritage: Helm
    release: infra-netdata
    chart: netdata-1.1.11
spec:
  allowPrivilegeEscalation: true
  allowedCapabilities:
  - '*'
  fsGroup:
    rule: RunAsAny
  hostIPC: true
  hostNetwork: true
  hostPID: true
  hostPorts:
  - max: 65535
    min: 0
  privileged: true
  runAsUser:
    rule: RunAsAny
  seLinux:
    rule: RunAsAny
  supplementalGroups:
    rule: RunAsAny
  volumes:
  - '*'
---
# Source: netdata/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: netdata-conf-master
  labels:
    app: netdata
    chart: netdata-1.1.11
    release: infra-netdata
    heritage: Helm
data:
  health:     |
      SEND_EMAIL="NO"
      SEND_SLACK="YES"
      SLACK_WEBHOOK_URL=""
      DEFAULT_RECIPIENT_SLACK=""
      role_recipients_slack[sysadmin]="${DEFAULT_RECIPIENT_SLACK}"
      role_recipients_slack[domainadmin]="${DEFAULT_RECIPIENT_SLACK}"
      role_recipients_slack[dba]="${DEFAULT_RECIPIENT_SLACK}"
      role_recipients_slack[webmaster]="${DEFAULT_RECIPIENT_SLACK}"
      role_recipients_slack[proxyadmin]="${DEFAULT_RECIPIENT_SLACK}"
      role_recipients_slack[sitemgr]="${DEFAULT_RECIPIENT_SLACK}"
  netdata:     |
      [global]
        memory mode = save
        bind to = 0.0.0.0:19999
      [plugins]
        cgroups = no
        tc = no
        enable running new plugins = no
        check for new plugins every = 72000
        python.d = no
        charts.d = no
        go.d = no
        node.d = no
        apps = no
        proc = no
        idlejitter = no
        diskspace = no
        micro.d = yes
      [plugin:micro.d]
        command options = --registry=etcd --registry_address=etcd-cluster-client

  stream:     |
      [B8E09BDC-AEE6-4A5C-8688-16B2D2024D9A]
        enabled = yes
        history = 3600
        default memory mode = save
        health enabled by default = auto
        allow from = *
---
# Source: netdata/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: netdata-conf-slave
  labels:
    app: netdata
    chart: netdata-1.1.11
    release: infra-netdata
    heritage: Helm
data:
  coredns:     |
      update_every: 1
      autodetection_retry: 0
      jobs:
        - url: http://127.0.0.1:9153/metrics
  kubelet:     |
      update_every: 1
      autodetection_retry: 0
      jobs:
        - url: http://127.0.0.1:10255/metrics
  kubeproxy:     |
      update_every: 1
      autodetection_retry: 0
      jobs:
        - url: http://127.0.0.1:10249/metrics
  netdata:     |
      [global]
        memory mode = none
      [health]
        enabled = no
      [plugins]
        micro.d = no
  stream:     |
      [stream]
        enabled = yes
        destination = netdata:19999
        api key = B8E09BDC-AEE6-4A5C-8688-16B2D2024D9A
        timeout seconds = 60
        buffer size bytes = 1048576
        reconnect delay seconds = 5
        initial clock resync iterations = 60
---
# Source: netdata/templates/serviceaccount.yaml
kind: ServiceAccount
apiVersion: v1
metadata:
  labels:
    app: netdata
    chart: netdata-1.1.11
    release: infra-netdata
    heritage: Helm
  name: netdata
---
# Source: netdata/templates/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: infra-netdata
  labels:
    app: netdata
    chart: netdata-1.1.11
    release: infra-netdata
    heritage: Helm
rules:
- apiGroups: [""]
  resources: ["services", "events", "endpoints", "pods", "nodes", "componentstatuses", "nodes/proxy" ]
  verbs: ["get", "list", "watch"]
- apiGroups: [""]
  resources: ["resourcequotas"]
  verbs: ["get", "list"]
- apiGroups: ["extensions"]
  resources: ["ingresses"]
  verbs: ["get", "list", "watch"]
- nonResourceURLs: ["/version", "/healthz", "/metrics"]
  verbs: ["get"]
- apiGroups: [""]
  resources: ["nodes/metrics", "nodes/spec"]
  verbs: ["get"]
---
# Source: netdata/templates/psp-clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: infra-netdata-psp
  labels:
    app: netdata
    chart: netdata-1.1.11
    release: infra-netdata
    heritage: Helm
rules:
- apiGroups: ['policy']
  resources: ['podsecuritypolicies']
  verbs:     ['use']
  resourceNames:
  - infra-netdata-psp
---
# Source: netdata/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: infra-netdata
  labels:
    app: netdata
    chart: netdata-1.1.11
    release: infra-netdata
    heritage: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: infra-netdata
subjects:
- kind: ServiceAccount
  name: netdata
  namespace: default
---
# Source: netdata/templates/psp-clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: infra-netdata-psp
  labels:
    app: netdata
    chart: netdata-1.1.11
    release: infra-netdata
    heritage: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: infra-netdata-psp
subjects:
- kind: ServiceAccount
  name: netdata
  namespace: default
---
# Source: netdata/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: netdata
  labels:
    app: netdata
    chart: netdata-1.1.11
    release: infra-netdata
    heritage: Helm
    role: master
spec:
  type: ClusterIP
  ports:
    - port: 19999
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app: netdata
    release: infra-netdata
    role: master
---
# Source: netdata/templates/daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: netdata-slave
  labels:
    app: netdata
    chart: netdata-1.1.11
    release: infra-netdata
    heritage: Helm
    role: slave
spec:
  selector:
    matchLabels:
      app: netdata
      release: infra-netdata
      role: slave
  template:
    metadata:
      annotations:
        container.apparmor.security.beta.kubernetes.io/netdata: unconfined
        checksum/config: 340f8dc578ab1a3bddb87165229b81bd5260ec8b0a0e5d5ae7a4b4d16b9760ca
      labels:
        app: netdata
        release: infra-netdata
        role: slave
    spec:
      serviceAccountName: netdata
      restartPolicy: Always
      hostPID: true
      hostIPC: true
      hostNetwork: true
      initContainers:
      containers:
        - name: netdata
          image: "micro/netdata:latest"
          imagePullPolicy: Always
          env:
            - name: MY_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: MY_POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","killall netdata; while killall -0 netdata; do sleep 1; done"]
          ports:
            - name: http
              containerPort: 19999
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /api/v1/info
              port: http
            timeoutSeconds: 1
            periodSeconds: 30
            successThreshold: 1
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /api/v1/info
              port: http
            timeoutSeconds: 1
            periodSeconds: 30
            successThreshold: 1
            failureThreshold: 3
          volumeMounts:
            - name: proc
              readOnly: true
              mountPath: /host/proc
            - name: run
              mountPath: /var/run/docker.sock
            - name: sys
              mountPath: /host/sys
            - name: config
              mountPath: /etc/netdata/go.d/coredns.conf
              subPath: coredns
            - name: config
              mountPath: /etc/netdata/go.d/k8s_kubelet.conf
              subPath: kubelet
            - name: config
              mountPath: /etc/netdata/go.d/k8s_kubeproxy.conf
              subPath: kubeproxy
            - name: config
              mountPath: /etc/netdata/netdata.conf
              subPath: netdata
            - name: config
              mountPath: /etc/netdata/stream.conf
              subPath: stream
          securityContext:
            capabilities:
              add:
                - SYS_PTRACE
                - SYS_ADMIN
          resources:
            {}
      tolerations:
        - effect: NoSchedule
          operator: Exists
      volumes:
        - name: proc
          hostPath:
            path: /proc
        - name: run
          hostPath:
            path: /var/run/docker.sock
        - name: sys
          hostPath:
            path: /sys
        - name: config
          configMap:
            name: netdata-conf-slave
      dnsPolicy: ClusterFirstWithHostNet
---
# Source: netdata/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: netdata-master
  labels:
    app: netdata
    chart: netdata-1.1.11
    release: infra-netdata
    heritage: Helm
    role: master
spec:
  serviceName: netdata
  replicas: 1
  selector:
    matchLabels:
      app: netdata
      release: infra-netdata
      role: master
  template:
    metadata:
      labels:
        app: netdata
        release: infra-netdata
        role: master
      annotations:
        checksum/config: 340f8dc578ab1a3bddb87165229b81bd5260ec8b0a0e5d5ae7a4b4d16b9760ca
    spec:
      securityContext:
        fsGroup: 201
      serviceAccountName: netdata
      initContainers:
      containers:
        - name: netdata
          image: "micro/netdata:latest"
          imagePullPolicy: Always
          env:
            - name: MY_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: MY_POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","killall netdata; while killall -0 netdata; do sleep 1; done"]
          ports:
            - name: http
              containerPort: 19999
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /api/v1/info
              port: http
            timeoutSeconds: 1
            periodSeconds: 30
            successThreshold: 1
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /api/v1/info
              port: http
            timeoutSeconds: 1
            periodSeconds: 30
            successThreshold: 1
            failureThreshold: 3
          volumeMounts:
            - name: config
              mountPath: /etc/netdata/health_alarm_notify.conf
              subPath: health
            - name: config
              mountPath: /etc/netdata/netdata.conf
              subPath: netdata
            - name: config
              mountPath: /etc/netdata/stream.conf
              subPath: stream
          resources:
            {}
      volumes:
        - name: config
          configMap:
            name: netdata-conf-master
